{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize a provided dataset and aims to classify tweets as either \"Relevant\" or \"Not Relevant\" using Doc2Vec and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Collecting Tweets](01-Gathering-Data.ipynb)\n",
    "1. [Feature Engineering with TF-IDF](02-Feature-Engineering.ipynb)\n",
    "1. [Benchmark Model](03-Benchmark-Model.ipynb)\n",
    "1. [Feature Engineering & Model Tuning with Doc2Vec](04-Model-Tuning.ipynb)\n",
    "1. [Making Predictions on Test Data](05-Making-Predictions.ipynb)\n",
    "1. [Visualizing a Disaster Event](06-Time-Series-Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "import time\n",
    "import pickle\n",
    "import gensim\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training data consists of 10,877 disaster-related tweets published by [Figure Eight](https://www.figure-eight.com/data-for-everyone/) on September 4th, 2015. \n",
    " - \"Contributors looked at over 10,000 tweets culled with a variety of searches like 'ablaze', 'quarantine', and 'pandemonium', then noted whether the tweet referred to a disaster event (as opposed to a joke with the word or a movie review or something non-disastrous).\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "df = pd.read_csv('../data/datasets/socialmedia-disaster-tweets-DFE.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>choose_one:confidence</th>\n",
       "      <th>choose_one_gold</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778243823</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778243824</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>778243825</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>778243826</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778243827</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  778243823     True      golden                 156               NaN   \n",
       "1  778243824     True      golden                 152               NaN   \n",
       "2  778243825     True      golden                 137               NaN   \n",
       "3  778243826     True      golden                 136               NaN   \n",
       "4  778243827     True      golden                 138               NaN   \n",
       "\n",
       "  choose_one  choose_one:confidence choose_one_gold keyword location  \\\n",
       "0   Relevant                 1.0000        Relevant     NaN      NaN   \n",
       "1   Relevant                 1.0000        Relevant     NaN      NaN   \n",
       "2   Relevant                 1.0000        Relevant     NaN      NaN   \n",
       "3   Relevant                 0.9603        Relevant     NaN      NaN   \n",
       "4   Relevant                 1.0000        Relevant     NaN      NaN   \n",
       "\n",
       "                                                text  tweetid  userid  \n",
       "0                 Just happened a terrible car crash      1.0     NaN  \n",
       "1  Our Deeds are the Reason of this #earthquake M...     13.0     NaN  \n",
       "2  Heard about #earthquake is different cities, s...     14.0     NaN  \n",
       "3  there is a forest fire at spot pond, geese are...     15.0     NaN  \n",
       "4             Forest fire near La Ronge Sask. Canada     16.0     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10876"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of observations\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows labeled 'can't decide'  for our target variable\n",
    "df = df[df['choose_one'] != 'Can\\'t Decide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Relevant    0.569705\n",
       "Relevant        0.430295\n",
       "Name: choose_one, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relevant variable\n",
    "df['choose_one'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10860"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create binary target column\n",
    "df['target'] = df['choose_one'].map(lambda x: 1 if x == 'Relevant' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After dropping tweets that could not be classified as either \"Relevant\" or \"Not Relevant\", we are left with 10,860 observations. \n",
    "- A baseline accuracy rate for our model is 57%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>This whole podcast explosion thing has been we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>If Shantae doesn't get in Smash I will destroy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9745</th>\n",
       "      <td>Robert Gagnon reviews the catastrophe of impos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9060</th>\n",
       "      <td>[CLIP] Top-down coercion - The structural weak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>Achievement Unlocked: Replaced Light Socket; D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "4987  This whole podcast explosion thing has been we...       0\n",
       "3658  If Shantae doesn't get in Smash I will destroy...       0\n",
       "9745  Robert Gagnon reviews the catastrophe of impos...       1\n",
       "9060  [CLIP] Top-down coercion - The structural weak...       0\n",
       "4408  Achievement Unlocked: Replaced Light Socket; D...       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split keeping target variable (separate y variable not necessary)\n",
    "train, test = train_test_split(df[['text','target']], stratify = df['target'], random_state=42)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate lemmatizer, tokenizer, and stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "#create set of stopwords from sklearn and add a few more words\n",
    "stops = set(stopwords.words('english'))\n",
    "more_stops = ['xb','amp']\n",
    "stops.update(more_stops)\n",
    "\n",
    "#function to clean text\n",
    "def to_words(raw_text):\n",
    "    #remove links \n",
    "    raw_text = re.sub('(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$', '', raw_text)\n",
    "    #tokenize\n",
    "    words = tokenizer.tokenize(raw_text.lower())\n",
    "    #remove stop words and lemmatize\n",
    "    meaningful_words = [lemmatizer.lemmatize(w) for w in words if not w in stops]\n",
    "    #returns a list of words\n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and export clean training data\n",
    "\n",
    "train_clean = pd.DataFrame(train['text'].map(lambda x: to_words(x)),columns = ['text'])\n",
    "train_clean['target'] = train['target']\n",
    "test_clean = pd.DataFrame(test['text'].map(lambda x: to_words(x)), columns = ['text'])\n",
    "test_clean['target'] = test['target']\n",
    "\n",
    "train_clean.to_csv('../data/datasets/train_clean.csv')\n",
    "test_clean.to_csv('../data/datasets/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TaggedDocument object array for our train and test data\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=to_words(r['text']), tags=[r['target']]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=to_words(r['text']), tags=[r['target']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4987    ([whole, podcast, explosion, thing, weird, rep...\n",
       "3658    ([shantae, get, smash, destroy, wii, u, shanta...\n",
       "9745    ([robert, gagnon, review, catastrophe, imposin...\n",
       "9060    ([clip, top, coercion, structural, weakness, e...\n",
       "4408    ([achievement, unlocked, replaced, light, sock...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec Distributed Bag of Words (DBOW) model\n",
    "- We use Doc2Vec to engineer paragraph vectors for tweets\n",
    "- The following procedures are a modification of Susan Li's example: [Multi-Class Text Classification with Doc2Vec & Logistic Regression](https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4)\n",
    "- \"DBOW is the doc2vec model analogous to Skip-gram model in word2vec. The paragraph vectors are obtained by training a neural network on the task of predicting a probability distribution of words in a paragraph given a randomly-sampled word from the paragraph.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function accepts a trained doc2vec model and TaggedDocument object\n",
    "def get_vectors(model, tagged_docs):\n",
    "    tweets = tagged_docs.values\n",
    "    tag, vector = zip(*[(t.tags[0], model.infer_vector(t.words, steps=20)) for t in tweets])\n",
    "    #returns the tag and paragraph vector\n",
    "    return tag, vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gridsearch doc2vec model\n",
    "# t0 = time.time()\n",
    "# sizes = [50,100,200,300]\n",
    "# windows = [5,8,10,15,20]\n",
    "# counts = [1,5,10]\n",
    "# summaries_dbow = []\n",
    "\n",
    "# for size in sizes:\n",
    "#     for window in windows:\n",
    "#         for count in counts:\n",
    "#             model_dbow = Doc2Vec(dm=0, vector_size=size, negative=15, window=window, \n",
    "#                                  hs=0, min_count=count, sample = 0, workers=cores)\n",
    "#             model_dbow.build_vocab([x for x in train_tagged.values])\n",
    "\n",
    "#             model_dbow.train(utils.shuffle([x for x in train_tagged.values]), \n",
    "#                                  total_examples=len(train_tagged.values), epochs=15)            \n",
    "\n",
    "#             y_train, X_train = get_vectors(model_dbow, train_tagged)\n",
    "#             y_test, X_test = get_vectors(model_dbow, test_tagged)\n",
    "#             logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "#             logreg.fit(X_train, y_train)\n",
    "\n",
    "#             y_train_pred = logreg.predict(X_train)\n",
    "#             y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "#             summary = {}\n",
    "#             summary['Size']      = size\n",
    "#             summary['Window']    = window\n",
    "#             summary['Count']     = count\n",
    "#             summary['Train_Acc'] = accuracy_score(y_train, y_train_pred)\n",
    "#             summary['Test_Acc']  = accuracy_score(y_test, y_test_pred)\n",
    "#             summary['Train_F1']  = f1_score(y_train, y_train_pred)\n",
    "#             summary['Test_F1']   = f1_score(y_test, y_test_pred)\n",
    "#             summary['CV_Score']  = cross_val_score(logreg, X_train, y_train, cv = 3).mean()\n",
    "#             summary['Train_Report'] = classification_report(y_train,y_train_pred)\n",
    "#             summary['Test_Report'] = classification_report(y_test,y_test_pred)\n",
    "            \n",
    "#             summaries_dbow.append(summary)\n",
    "\n",
    "# print(time.time()-t0)\n",
    "# summaries_dbow_df = pd.DataFrame(summaries_dbow)\n",
    "# summaries_dbow_df.sort_values(by='Test_Acc',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- After doing a \"GridSearch\" to tune our Doc2Vec hyperparameters, we instatiate and train our Doc2Vec and Logistic Regression Model below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing and Exporting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy 0.8379373848987108\n",
      "Final model F1 score: 0.8359878347374353\n",
      "Final model CV score: 0.8281131312914726\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "\n",
    "df_tagged = df.apply(\n",
    "    lambda r: TaggedDocument(words=to_words(r['text']), tags=[r['target']]), axis=1)\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=15, window=15, \n",
    "                     hs=0, min_count=5, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in df_tagged.values])\n",
    "\n",
    "model_dbow.train(utils.shuffle([x for x in df_tagged.values]), \n",
    "                                 total_examples=len(df_tagged.values), epochs=15)            \n",
    "\n",
    "\n",
    "get_vectors(model_dbow, df_tagged)\n",
    "\n",
    "y, X = get_vectors(model_dbow, train_tagged)\n",
    "logreg.fit(X, y)\n",
    "y_pred = logreg.predict(X)\n",
    "\n",
    "print('Final model accuracy %s' % accuracy_score(y, y_pred))\n",
    "print('Final model F1 score: {}'.format(f1_score(y, y_pred, average='weighted')))\n",
    "print('Final model CV score: {}'.format(cross_val_score(logreg, X, y, cv = 3).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export package\n",
    "models = {'model_dbow':model_dbow,\n",
    "         'logreg':logreg}\n",
    "\n",
    "pickle.dump(models, open('../data/pickles/models.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
